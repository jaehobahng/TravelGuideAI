{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid\n"
     ]
    }
   ],
   "source": [
    "from ollama import chat\n",
    "from ollama import ChatResponse\n",
    "\n",
    "# Define the system prompt to guide the model's behavior\n",
    "system_prompt = {\n",
    "    'role': 'system',\n",
    "    'content': (\n",
    "        \"\"\"You are a travel assistant. Your task is to determine if the user's prompt specifies:\n",
    "        1. A starting city (sometimes denoted by \"from\").\n",
    "        2. A destination city (sometimes denoted by \"to\").\n",
    "\n",
    "        If either one is missing, explain nicely what information the user needs to input, \n",
    "\n",
    "        If both are present, respond only with 'VALID QUERY' and nothing else.\"\"\"\n",
    "    )\n",
    "}\n",
    "\n",
    "# Example user prompt (replace with actual user input)\n",
    "# user_prompt = \"Why is the sky blue?\"\n",
    "user_prompt = \"I want to book a flight from chicago to newyork on january 1 2025\"\n",
    "\n",
    "# Call the chat model with both the system prompt and the user prompt\n",
    "validation_response : ChatResponse = chat(model='llama3.2', messages=[\n",
    "    system_prompt,\n",
    "    {'role': 'user', 'content': user_prompt}],\n",
    "    stream=False,\n",
    "    options={\"temperature\":0.1}\n",
    ")\n",
    "\n",
    "validation_output = validation_response['message']['content']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for chunk in validation_output:\n",
    "#   print(chunk['message']['content'], end='', flush=True)\n",
    "\n",
    "if 'VALID QUERY' in validation_output:\n",
    "    # If input is valid, query the second LLM\n",
    "    print('valid')\n",
    "    # second_llm_output = query_second_llm(user_prompt)\n",
    "    # print(second_llm_output)\n",
    "else:\n",
    "    # If input is invalid, respond with the validation output\n",
    "    print(validation_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Define the system prompt to guide the model's behavior\n",
    "system_prompt = {\n",
    "    'role': 'system',\n",
    "    'content': (\n",
    "        \"\"\"\n",
    "        You are a data parser for a travel related input.\n",
    "        Your task is to read user input, and parse it into json format like below based on starting location, destination, and date.\n",
    "        Only give the output as json format\n",
    "\n",
    "        {\"endpoint\": \"/shopping/flight-offers\", \"params\": {\"originLocationCode\": \"3 letter code\", \"destinationLocationCode\": \"3 letter code\", \"departureDate\": \"date format\", \"adults\": 1}}\n",
    "        \"\"\"\n",
    "    )\n",
    "}\n",
    "\n",
    "# Call the chat model with both the system prompt and the user prompt\n",
    "json_response : ChatResponse = chat(model='llama3.2', messages=[\n",
    "    system_prompt,\n",
    "    {'role': 'user', 'content': user_prompt}],\n",
    "    stream=False,\n",
    "    options={\"temperature\":0.1}\n",
    ")\n",
    "\n",
    "json_response = json_response['message']['content']\n",
    "response_json = json.loads(json_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from amadeus import Client, ResponseError\n",
    "\n",
    "amadeus = Client(\n",
    "    client_id='aQAGtf2RwvH4MRoacY1zeaDqTNKjZaef',\n",
    "    client_secret='W0peyMi27F82EjG7'\n",
    ")\n",
    "\n",
    "try:\n",
    "    response = amadeus.shopping.flight_offers_search.get(\n",
    "        originLocationCode=response_json['params']['originLocationCode'],\n",
    "        destinationLocationCode=response_json['params']['destinationLocationCode'],\n",
    "        departureDate=response_json['params']['departureDate'],\n",
    "        adults=response_json['params']['adults'])\n",
    "    \n",
    "    rd = response.data\n",
    "except ResponseError as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the number of stops\n",
    "def get_num_stops(offer):\n",
    "    return len(offer['itineraries'][0]['segments']) - 1\n",
    "\n",
    "\n",
    "\n",
    "# Function to filter by stops and cabin class\n",
    "def filter_by_stops_and_cabin(data, stops, cabin_class, top_n):\n",
    "    # Filter by number of stops\n",
    "    filtered_by_stops = [offer for offer in data if get_num_stops(offer) == stops]\n",
    "    \n",
    "    # Filter by cabin class\n",
    "    filtered_by_cabin = [\n",
    "        offer for offer in filtered_by_stops \n",
    "        if all(fare['cabin'] == cabin_class for fare in offer['travelerPricings'][0]['fareDetailsBySegment'])\n",
    "    ]\n",
    "    \n",
    "    # Sort by price and return the top `n` offers\n",
    "    return sorted(filtered_by_cabin, key=lambda x: float(x['price']['total']))[:top_n]\n",
    "\n",
    "n = 2  # Number of top choices to return\n",
    "\n",
    "# Get results for 0-stop flights in economy and business\n",
    "zero_stops_economy = filter_by_stops_and_cabin(rd, stops=0, cabin_class=\"ECONOMY\", top_n=n)\n",
    "zero_stops_business = filter_by_stops_and_cabin(rd, stops=0, cabin_class=\"PREMIUM_ECONOMY\", top_n=n)\n",
    "\n",
    "# Get results for 1-stop flights in economy and business\n",
    "one_stop_economy = filter_by_stops_and_cabin(rd, stops=1, cabin_class=\"ECONOMY\", top_n=n)\n",
    "one_stop_business = filter_by_stops_and_cabin(rd, stops=1, cabin_class=\"PREMIUM_ECONOMY\", top_n=n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "def feature_engineering(data, keys_to_extract):\n",
    "    \"\"\"\n",
    "    Adds a 'flightinfo' key and a 'layover_minutes' key to each item in the dataset.\n",
    "    - 'flightinfo': Merges details from segments and fareDetailsBySegment.\n",
    "    - 'layover_minutes': Calculates the layover time between the first arrival and second departure.\n",
    "\n",
    "    Parameters:\n",
    "    - data (list): A list of dictionaries, where each dictionary contains 'itineraries' \n",
    "                   and 'travelerPricings' keys.\n",
    "\n",
    "    Returns:\n",
    "    - list: The updated dataset with 'flightinfo' and 'layover_minutes' added to each item.\n",
    "    \"\"\"\n",
    "    for item in data:\n",
    "        # Extract segments and fare details\n",
    "        segments = item['itineraries'][0]['segments']\n",
    "        fare_details = item['travelerPricings'][0]['fareDetailsBySegment']\n",
    "\n",
    "        # Merge flightinfo\n",
    "        merged_flight_info = []\n",
    "        for segment in segments:\n",
    "            for fare in fare_details:\n",
    "                if segment['id'] == fare['segmentId']:\n",
    "                    merged_flight_info.append({\n",
    "                        'departure': segment['departure'],\n",
    "                        'arrival': segment['arrival'],\n",
    "                        'carrierCode': segment['carrierCode'],\n",
    "                        'duration': segment['duration'],\n",
    "                        'cabin': fare['cabin'],\n",
    "                        # 'includedCheckedBags': fare['includedCheckedBags']\n",
    "                    })\n",
    "        item['flightinfo'] = merged_flight_info\n",
    "\n",
    "        # Calculate layover_minutes\n",
    "        if len(segments) > 1:  # Ensure there are at least two segments to calculate layover\n",
    "            first_arrival = segments[0]['arrival']['at']\n",
    "            second_departure = segments[1]['departure']['at']\n",
    "\n",
    "            # Convert times to datetime objects\n",
    "            first_arrival_time = datetime.fromisoformat(first_arrival)\n",
    "            second_departure_time = datetime.fromisoformat(second_departure)\n",
    "\n",
    "            # Calculate the time difference in minutes\n",
    "            time_difference_minutes = (second_departure_time - first_arrival_time).total_seconds() / 60\n",
    "            item['layover_minutes'] = time_difference_minutes\n",
    "        else:\n",
    "            item['layover_minutes'] = 0\n",
    "\n",
    "    data = [{key: item[key] for key in keys_to_extract if key in item} for item in data]\n",
    "\n",
    "    return data\n",
    "\n",
    "keys_to_extract = ['numberOfBookableSeats','flightinfo','layover_minutes','price']\n",
    "\n",
    "\n",
    "ze = feature_engineering(zero_stops_economy, keys_to_extract)\n",
    "zb = feature_engineering(zero_stops_business, keys_to_extract)\n",
    "oe = feature_engineering(one_stop_economy, keys_to_extract)\n",
    "ob = feature_engineering(one_stop_business, keys_to_extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome, traveler! I'm your tour guide today. We're going to explore the fascinating world of flight information.\n",
      "\n",
      "As we examine this JSON data, you'll notice that there are several key aspects of your flight that we can discuss. Let's break them down:\n",
      "\n",
      "1. **Flight Details**: You have a total of 7 bookable seats on this flight. The departure airport is ORD (O'Hare International Airport), and the arrival airport is JFK (John F. Kennedy International Airport). The flight duration is approximately 2 hours and 9 minutes.\n",
      "\n",
      "2. **Layover Information**: We don't have any layovers scheduled for you, as the layover time is just 0 minutes. This means you'll be straight from departure to arrival without any breaks in between.\n",
      "\n",
      "3. **Flight Price**: The total price of your ticket is €183.12 (Euros). This includes a base fare of €157.00 and some additional fees:\n",
      "\t* A checked bag fee of €37.95.\n",
      "\t* No other fees are applicable, as the supplier has waived them.\n",
      "\n",
      "Now that we've gone over these key aspects of your flight, I'd like to ask: Are you ready to proceed with booking this flight?"
     ]
    }
   ],
   "source": [
    "from ollama import chat\n",
    "from ollama import ChatResponse\n",
    "\n",
    "# Define the system prompt to guide the model's behavior\n",
    "system_prompt = {\n",
    "    'role': 'system',\n",
    "    'content': (\n",
    "        \"\"\"\n",
    "        You are a travel assistant.\n",
    "        The input will be a json format input with flight information\n",
    "        Given the information, summarize the choices the user has regarding the information.\n",
    "        Speak as if you are the tour guide ans speaking to a tourist.\n",
    "        \n",
    "        \"\"\"\n",
    "    )\n",
    "}\n",
    "\n",
    "# Example user prompt (replace with actual user input)\n",
    "# user_prompt = \"Why is the sky blue?\"\n",
    "user_prompt = str(ze)\n",
    "\n",
    "# Call the chat model with both the system prompt and the user prompt\n",
    "response : ChatResponse = chat(model='llama3.2', messages=[\n",
    "    system_prompt,\n",
    "    {'role': 'user', 'content': user_prompt}],\n",
    "    stream=True,\n",
    "    options={\"temperature\":0.1}\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "  print(chunk['message']['content'], end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import chat\n",
    "from ollama import ChatResponse\n",
    "import time\n",
    "import json\n",
    "from amadeus import Client, ResponseError\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "def stream_output(output, delay=0.05):\n",
    "    for char in output.split():\n",
    "        print(char, end=' ', flush=True)\n",
    "        time.sleep(delay)\n",
    "\n",
    "\n",
    "# Function to calculate the number of stops\n",
    "def get_num_stops(offer):\n",
    "    return len(offer['itineraries'][0]['segments']) - 1\n",
    "\n",
    "\n",
    "\n",
    "# Function to filter by stops and cabin class\n",
    "def filter_by_stops_and_cabin(data, stops, cabin_class, top_n):\n",
    "    # Filter by number of stops\n",
    "    filtered_by_stops = [offer for offer in data if get_num_stops(offer) == stops]\n",
    "    \n",
    "    # Filter by cabin class\n",
    "    filtered_by_cabin = [\n",
    "        offer for offer in filtered_by_stops \n",
    "        if all(fare['cabin'] == cabin_class for fare in offer['travelerPricings'][0]['fareDetailsBySegment'])\n",
    "    ]\n",
    "    \n",
    "    # Sort by price and return the top `n` offers\n",
    "    return sorted(filtered_by_cabin, key=lambda x: float(x['price']['total']))[:top_n]\n",
    "\n",
    "def feature_engineering(data, keys_to_extract):\n",
    "    \"\"\"\n",
    "    Adds a 'flightinfo' key and a 'layover_minutes' key to each item in the dataset.\n",
    "    - 'flightinfo': Merges details from segments and fareDetailsBySegment.\n",
    "    - 'layover_minutes': Calculates the layover time between the first arrival and second departure.\n",
    "\n",
    "    Parameters:\n",
    "    - data (list): A list of dictionaries, where each dictionary contains 'itineraries' \n",
    "                and 'travelerPricings' keys.\n",
    "\n",
    "    Returns:\n",
    "    - list: The updated dataset with 'flightinfo' and 'layover_minutes' added to each item.\n",
    "    \"\"\"\n",
    "    for item in data:\n",
    "        # Extract segments and fare details\n",
    "        segments = item['itineraries'][0]['segments']\n",
    "        fare_details = item['travelerPricings'][0]['fareDetailsBySegment']\n",
    "\n",
    "        # Merge flightinfo\n",
    "        merged_flight_info = []\n",
    "        for segment in segments:\n",
    "            for fare in fare_details:\n",
    "                if segment['id'] == fare['segmentId']:\n",
    "                    merged_flight_info.append({\n",
    "                        'departure': segment['departure'],\n",
    "                        'arrival': segment['arrival'],\n",
    "                        'carrierCode': segment['carrierCode'],\n",
    "                        'duration': segment['duration'],\n",
    "                        'cabin': fare['cabin'],\n",
    "                        # 'includedCheckedBags': fare['includedCheckedBags']\n",
    "                    })\n",
    "        item['flightinfo'] = merged_flight_info\n",
    "\n",
    "        # Calculate layover_minutes\n",
    "        if len(segments) > 1:  # Ensure there are at least two segments to calculate layover\n",
    "            first_arrival = segments[0]['arrival']['at']\n",
    "            second_departure = segments[1]['departure']['at']\n",
    "\n",
    "            # Convert times to datetime objects\n",
    "            first_arrival_time = datetime.fromisoformat(first_arrival)\n",
    "            second_departure_time = datetime.fromisoformat(second_departure)\n",
    "\n",
    "            # Calculate the time difference in minutes\n",
    "            time_difference_minutes = (second_departure_time - first_arrival_time).total_seconds() / 60\n",
    "            item['layover_minutes'] = time_difference_minutes\n",
    "        else:\n",
    "            item['layover_minutes'] = 0\n",
    "\n",
    "    data = [{key: item[key] for key in keys_to_extract if key in item} for item in data]\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def NomadAI(prompt):\n",
    "\n",
    "    # Define the system prompt to guide the model's behavior\n",
    "    system_prompt = {\n",
    "        'role': 'system',\n",
    "        'content': (\n",
    "            \"\"\"You are a travel assistant. Your task is to determine if the user's prompt specifies:\n",
    "            1. A starting city (sometimes denoted by \"from\").\n",
    "            2. A destination city (sometimes denoted by \"to\").\n",
    "\n",
    "            If either one is missing, explain nicely what information the user needs to input, \n",
    "\n",
    "            If both are present, respond only with 'VALID QUERY' and nothing else.\"\"\"\n",
    "        )\n",
    "    }\n",
    "\n",
    "    # Example user prompt (replace with actual user input)\n",
    "    # user_prompt = \"Why is the sky blue?\"\n",
    "    # user_prompt = \"I want to book a flight from chicago to newyork on january 1 2025\"\n",
    "\n",
    "    # Call the chat model with both the system prompt and the user prompt\n",
    "    validation_response : ChatResponse = chat(model='llama3.2', messages=[\n",
    "        system_prompt,\n",
    "        {'role': 'user', 'content': prompt}],\n",
    "        stream=False,\n",
    "        options={\"temperature\":0.1}\n",
    "    )\n",
    "\n",
    "    validation_output = validation_response['message']['content']\n",
    "\n",
    "    # for chunk in validation_output:\n",
    "    #   print(chunk['message']['content'], end='', flush=True)\n",
    "\n",
    "    if 'VALID QUERY' in validation_output:\n",
    "        # If input is valid, query the second LLM\n",
    "        pass\n",
    "        # second_llm_output = query_second_llm(user_prompt)\n",
    "        # print(second_llm_output)\n",
    "    else:\n",
    "        # If input is invalid, respond with the validation output\n",
    "        return stream_output(validation_output)\n",
    "\n",
    "\n",
    "\n",
    "    # FINE TUNE MOEL GOES HERE\n",
    "    # Define the system prompt to guide the model's behavior\n",
    "    system_prompt = {\n",
    "        'role': 'system',\n",
    "        'content': (\n",
    "            \"\"\"\n",
    "            You are a data parser for a travel related input.\n",
    "            Your task is to read user input, and parse it into json format like below based on starting location, destination, and date.\n",
    "            Only give the output as json format\n",
    "\n",
    "            {\"endpoint\": \"/shopping/flight-offers\", \"params\": {\"originLocationCode\": \"3 letter code\", \"destinationLocationCode\": \"3 letter code\", \"departureDate\": \"date format\", \"adults\": 1}}\n",
    "            \"\"\"\n",
    "        )\n",
    "    }\n",
    "\n",
    "    # Call the chat model with both the system prompt and the user prompt\n",
    "    json_response : ChatResponse = chat(model='llama3.2', messages=[\n",
    "        system_prompt,\n",
    "        {'role': 'user', 'content': prompt}],\n",
    "        stream=False,\n",
    "        options={\"temperature\":0.1}\n",
    "    )\n",
    "\n",
    "    json_response = json_response['message']['content']\n",
    "    response_json = json.loads(json_response)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # API CALL TO AMADEUS\n",
    "    amadeus = Client(\n",
    "        client_id=os.getenv('AMADEUS_CLIENT_ID'),\n",
    "        client_secret=os.getenv('AMADEUS_CLIENT_SECRET')\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        response = amadeus.shopping.flight_offers_search.get(\n",
    "            originLocationCode=response_json['params']['originLocationCode'],\n",
    "            destinationLocationCode=response_json['params']['destinationLocationCode'],\n",
    "            departureDate=response_json['params']['departureDate'],\n",
    "            adults=response_json['params']['adults'])\n",
    "        \n",
    "        rd = response.data\n",
    "    except ResponseError as error:\n",
    "        print(error)\n",
    "\n",
    "    n = 2  # Number of top choices to return\n",
    "\n",
    "    # Get results for 0-stop flights in economy and business\n",
    "    zero_stops_economy = filter_by_stops_and_cabin(rd, stops=0, cabin_class=\"ECONOMY\", top_n=n)\n",
    "    zero_stops_business = filter_by_stops_and_cabin(rd, stops=0, cabin_class=\"PREMIUM_ECONOMY\", top_n=n)\n",
    "\n",
    "    # Get results for 1-stop flights in economy and business\n",
    "    one_stop_economy = filter_by_stops_and_cabin(rd, stops=1, cabin_class=\"ECONOMY\", top_n=n)\n",
    "    one_stop_business = filter_by_stops_and_cabin(rd, stops=1, cabin_class=\"PREMIUM_ECONOMY\", top_n=n)\n",
    "\n",
    "    keys_to_extract = ['numberOfBookableSeats','flightinfo','layover_minutes','price']\n",
    "\n",
    "    ze = feature_engineering(zero_stops_economy, keys_to_extract)\n",
    "    zb = feature_engineering(zero_stops_business, keys_to_extract)\n",
    "    oe = feature_engineering(one_stop_economy, keys_to_extract)\n",
    "    ob = feature_engineering(one_stop_business, keys_to_extract)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # JSON TO HUMAN OUTPUT\n",
    "    # Define the system prompt to guide the model's behavior\n",
    "    system_prompt = {\n",
    "        'role': 'system',\n",
    "        'content': (\n",
    "            \"\"\"\n",
    "            You are a travel assistant.\n",
    "            The input will be a json format input with flight information\n",
    "            Given the information, summarize the choices the user has regarding the information.\n",
    "            Speak as if you are explaining the details for a customer.\n",
    "            \n",
    "            \"\"\"\n",
    "        )\n",
    "    }\n",
    "\n",
    "    # Example user prompt (replace with actual user input)\n",
    "    # user_prompt = \"Why is the sky blue?\"\n",
    "    user_prompt = str(ze)\n",
    "\n",
    "    # Call the chat model with both the system prompt and the user prompt\n",
    "    response : ChatResponse = chat(model='llama3.2', messages=[\n",
    "        system_prompt,\n",
    "        {'role': 'user', 'content': user_prompt}],\n",
    "        stream=True,\n",
    "        options={\"temperature\":0.1}\n",
    "    )\n",
    "\n",
    "    for chunk in response:\n",
    "        print(chunk['message']['content'], end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to our travel assistance! I'd be happy to help you understand the details of your flight.\n",
      "\n",
      "Based on the information provided, here are the choices you have regarding your flight:\n",
      "\n",
      "1. **Flight Details**: You can see that your flight is departing from Chicago's O'Hare International Airport (ORD) and arriving at John F. Kennedy International Airport (JFK). The flight duration is approximately 2 hours and 9 minutes.\n",
      "\n",
      "2. **Seat Availability**: There are 7 bookable seats available on this flight, which means you can choose one of these seats when booking your ticket.\n",
      "\n",
      "3. **Layover Time**: You don't have any layovers scheduled for this flight, as the total travel time is just under 3 hours.\n",
      "\n",
      "4. **Flight Carrier**: The airline operating this flight is JetBlue (B6).\n",
      "\n",
      "5. **Additional Services**: There's an additional service charge of €37.95 for checked bags on your flight.\n",
      "\n",
      "6. **Price Breakdown**: Your total fare includes:\n",
      "\t* Base price: €157.00\n",
      "\t* Fees: €0.00 (no additional fees)\n",
      "\t* Additional services: €37.95 (checked bag fee)\n",
      "\n",
      "Your grand total comes out to be €183.12, which is the amount you'll need to pay for your ticket.\n",
      "\n",
      "Is there anything else I can help you with regarding this flight?"
     ]
    }
   ],
   "source": [
    "NomadAI(\"I want to book a flight from chicago to newyork on january 1 2025\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import chat\n",
    "from ollama import ChatResponse\n",
    "\n",
    "def query_refiner(log, prompt):\n",
    "    # Define the system prompt to guide the model's behavior\n",
    "    system_prompt = {\n",
    "        'role': 'system',\n",
    "        'content': (\n",
    "            \"\"\"\n",
    "            Given the following user query and conversation log, formulate a question that would be the most relevant to provide the user with an answer from a knowledge base.\n",
    "            Just output the new question\n",
    "            \"\"\"\n",
    "        )\n",
    "    }\n",
    "\n",
    "    # Call the chat model with both the system prompt and the user prompt\n",
    "    response : ChatResponse = chat(model='llama3.2', messages=[\n",
    "        system_prompt,\n",
    "        {'role': 'user', 'content': f\"Log : {log} / Prompt : {prompt}\"}],\n",
    "        stream=False,\n",
    "        options={\"temperature\":0.1}\n",
    "    )\n",
    "\n",
    "    return response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is India's economic relationship with the United States?\n"
     ]
    }
   ],
   "source": [
    "print(query_refiner({'user': 'How is the economomy in india', 'assistant':'Its doing great'}, \"What about the relationship with the united states\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_refiner(conversation, query):\n",
    "    response = openai.Completion.create(\n",
    "        model=\"text-davinci-003\",\n",
    "        prompt=f\"Given the following user query and conversation log, formulate a question that would be the most relevant to provide the user with an answer from a knowledge base.\\n\\nCONVERSATION LOG: \\n{conversation}\\n\\nQuery: {query}\\n\\nRefined Query:\",\n",
    "        temperature=0.7,\n",
    "        max_tokens=256,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "    )\n",
    "    return response['choices'][0]['text'].strip()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
