{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf62c83-fd76-4841-a8b4-17d4cd0c8107",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sagemaker-user/.conda/envs/llama_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "import os\n",
    "\n",
    "# Login to Hugging Face\n",
    "login(\"MY_TOKEN\") #hidden for security"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8db9079a-eba6-4ed8-9fe4-594786a05f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20095fdc-3b11-40ce-aeba-a4071b5556d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully accessed the model repository.\n"
     ]
    }
   ],
   "source": [
    "# import requests\n",
    "\n",
    "# model_url = \"https://huggingface.co/meta-llama/Llama-3.1-8B\"\n",
    "\n",
    "# try:\n",
    "#     response = requests.get(model_url)\n",
    "#     if response.status_code == 200:\n",
    "#         print(\"Successfully accessed the model repository.\")\n",
    "#     else:\n",
    "#         print(f\"Failed to access model repository. Status code: {response.status_code}\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Error accessing model repository: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c6bd221-8c02-4105-aad2-41b8db84df07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards: 100%|██████████| 4/4 [25:48<00:00, 387.05s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [02:02<00:00, 30.57s/it]\n"
     ]
    }
   ],
   "source": [
    "# from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# model_name = \"meta-llama/Llama-3.1-8B\"\n",
    "\n",
    "# # Optionally, specify a cache directory\n",
    "# cache_dir = \"./cache_llama_models\"\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True, cache_dir=cache_dir)\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     model_name,\n",
    "#     device_map=\"auto\",\n",
    "#     torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "#     trust_remote_code=True,\n",
    "#     cache_dir=cache_dir\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ad57cb3-ec70-4cf0-a3be-157d515a492b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from langchain import LLMChain, PromptTemplate\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "743dee8e-b4d2-43dc-8669-6d4f67844059",
   "metadata": {},
   "outputs": [],
   "source": [
    "HF_HUB_ENABLE_HF_TRANSFER=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921b5568-6d18-4ac7-9d8f-e4edec196d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoConfig, LlamaForCausalLM\n",
    "\n",
    "# Paths\n",
    "model_path = \"/home/sagemaker-user/Llama-3.1-8B/original/\"  # Path to consolidated.pth\n",
    "checkpoint_path = f\"{model_path}/consolidated.pth\"  # Full path to the weights\n",
    "tokenizer_id = \"meta-llama/Llama-3.1-8B\"  # Hugging Face model ID for tokenizer\n",
    "\n",
    "# Load tokenizer and config from Hugging Face\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_id)\n",
    "config = AutoConfig.from_pretrained(tokenizer_id)\n",
    "\n",
    "# Initialize the model with Hugging Face config\n",
    "model = LlamaForCausalLM(config)\n",
    "\n",
    "# Load weights from consolidated.pth\n",
    "state_dict = torch.load(checkpoint_path, map_location=\"cpu\")\n",
    "model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "# Move the model to the appropriate device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "\n",
    "# Set up a text-generation pipeline\n",
    "from transformers import pipeline\n",
    "\n",
    "text_gen = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")\n",
    "\n",
    "# Generate text\n",
    "output = text_gen(\"Hey, how are you doing today?\", max_length=50)\n",
    "print(output)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9219a1be-7dad-4628-86ff-2eda1b9e1a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  7.88it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "`checkpoint` should be the path to a file containing a whole state dict, or the index of a sharded checkpoint, or a folder containing a sharded checkpoint or the whole state dict, but got ./cache_llama_models/Llama-3.1-8B.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Ensure the cache directory exists\u001b[39;00m\n\u001b[1;32m     24\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(cache_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 26\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mload_checkpoint_and_dispatch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Use the correct directory containing the model weights\u001b[39;49;00m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# Automatically maps model parts to CPU/GPU\u001b[39;49;00m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moffload_disk\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Specify folder for offloading\u001b[39;49;00m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m     \u001b[49m\u001b[38;5;66;43;03m# Enable state dict offloading\u001b[39;49;00m\n\u001b[1;32m     32\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Load tokenizer\u001b[39;00m\n\u001b[1;32m     35\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m     36\u001b[0m     model_name, \n\u001b[1;32m     37\u001b[0m     trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     40\u001b[0m     truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m        \u001b[38;5;66;03m# Explicitly truncate inputs\u001b[39;00m\n\u001b[1;32m     41\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/llama_env/lib/python3.10/site-packages/accelerate/big_modeling.py:613\u001b[0m, in \u001b[0;36mload_checkpoint_and_dispatch\u001b[0;34m(model, checkpoint, device_map, max_memory, no_split_module_classes, offload_folder, offload_buffers, dtype, offload_state_dict, skip_keys, preload_module_classes, force_hooks, strict)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m offload_state_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisk\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m    612\u001b[0m     offload_state_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 613\u001b[0m \u001b[43mload_checkpoint_in_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m    \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m    \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m    \u001b[49m\u001b[43moffload_buffers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_buffers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    624\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/.conda/envs/llama_env/lib/python3.10/site-packages/accelerate/utils/modeling.py:1691\u001b[0m, in \u001b[0;36mload_checkpoint_in_model\u001b[0;34m(model, checkpoint, device_map, offload_folder, dtype, offload_state_dict, offload_buffers, keep_in_fp32_modules, offload_8bit_bnb, strict)\u001b[0m\n\u001b[1;32m   1687\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1688\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcheckpoint\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m containing more than one `.index.json` file, delete the irrelevant ones.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1689\u001b[0m             )\n\u001b[1;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1691\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1692\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`checkpoint` should be the path to a file containing a whole state dict, or the index of a sharded \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1693\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpoint, or a folder containing a sharded checkpoint or the whole state dict, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcheckpoint\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1694\u001b[0m     )\n\u001b[1;32m   1696\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index_filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1697\u001b[0m     checkpoint_folder \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplit(index_filename)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: `checkpoint` should be the path to a file containing a whole state dict, or the index of a sharded checkpoint, or a folder containing a sharded checkpoint or the whole state dict, but got ./cache_llama_models/Llama-3.1-8B."
     ]
    }
   ],
   "source": [
    "import os\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from accelerate import init_empty_weights, load_checkpoint_and_dispatch\n",
    "import torch\n",
    "\n",
    "# Define model details\n",
    "model_name = \"meta-llama/Llama-3.1-8B\"\n",
    "\n",
    "# Specify an absolute where llama\n",
    "cache_dir = \"./cache_llama_models\"\n",
    "\n",
    "# Ensure the cache directory exists\n",
    "os.makedirs(cache_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "# Ensure the cache directory exists\n",
    "os.makedirs(cache_dir, exist_ok=True)\n",
    "\n",
    "model = load_checkpoint_and_dispatch(\n",
    "    model,\n",
    "    checkpoint=checkpoint_dir,  # Use the correct directory containing the model weights\n",
    "    device_map=\"auto\",          # Automatically maps model parts to CPU/GPU  # Specify folder for offloading     # Enable state dict offloading\n",
    ")\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name, \n",
    "    trust_remote_code=True, \n",
    "    cache_dir=cache_dir,\n",
    "    padding_side=\"right\",  # Ensure padding on the correct side\n",
    "    truncation=True        # Explicitly truncate inputs\n",
    ")\n",
    "\n",
    "# Example pipeline usage (optional)\n",
    "pipeline_example = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=0 if torch.cuda.is_available() else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66f43fc-79a3-452e-8400-a9e01728b898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a text-generation pipeline with adjusted parameters\n",
    "text_gen_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6618145-6a50-4680-bab9-7a54811019e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the system prompt\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "Generate a JSON object where:\n",
    "1. \"input\" is a single string where a user requests information for a flight from one location to another and asks about a specific day, with additional information sometimes added like number of passengers, class, if only non-stop, etc. This is provided in plain text, not JSON.\n",
    "2. \"output\" contains the corresponding Amadeus API call in JSON format:\n",
    "   - The \"action\" field is always [\"search_flights\"].\n",
    "   - The \"action_input\" field contains:\n",
    "     - \"origin\": A 3-letter city code for the departure location or airport 3 letter code if mentioned.\n",
    "     - \"destination\": A 3-letter city code for the arrival location or airport 3 letter code if mentioned.\n",
    "     - \"departure_date\": A date in \"YYYY-MM-DD\" format.\n",
    "     - \"adults\": An integer representing the number of adults (default is 1).\n",
    "     - Optional fields should be included if mentioned and returned as an empty string if not mentioned:\n",
    "       - \"return_date\": A date in \"YYYY-MM-DD\" format for the return flight.\n",
    "       - \"children\": An integer for the number of children.\n",
    "       - \"infants\": An integer for the number of infants.\n",
    "       - \"class\": One of \"ECONOMY\", \"PREMIUM_ECONOMY\", \"BUSINESS\", or \"FIRST\".\n",
    "       - \"nonStop\": A boolean indicating whether only non-stop flights are desired.\n",
    "       - \"maxPrice\": An integer specifying the maximum price.\n",
    "     - \"max\": Always set to 5.\n",
    "\n",
    "3. Generate one example per response object. Be variable in the input format and the output fields following the guidelines above.\n",
    "\"\"\"\n",
    "\n",
    "# Generate 10 examples with varying temperatures\n",
    "examples = []\n",
    "for i in range(10):\n",
    "    # Update temperature for diversity\n",
    "    temperature = 1\n",
    "\n",
    "    # Generate a response using the system prompt\n",
    "    response = pipeline(\n",
    "        SYSTEM_PROMPT,\n",
    "        max_length=512,\n",
    "        temperature=temperature,\n",
    "        num_return_sequences=1,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "    # Extract the generated text\n",
    "    generated_text = response[0][\"generated_text\"]\n",
    "\n",
    "    try:\n",
    "        # Parse the response and append it to the examples list\n",
    "        example = json.loads(generated_text)\n",
    "        examples.append(example)\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Failed to decode response at iteration {i + 1}: {generated_text}\")\n",
    "\n",
    "# Print all generated examples\n",
    "for idx, example in enumerate(examples):\n",
    "    print(f\"Example {idx + 1}:\")\n",
    "    print(json.dumps(example, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51eb688-4aea-40a9-8456-e28f88948b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "# SageMaker endpoint details\n",
    "endpoint_name = \"jumpstart-dft-llama-3-2-1b-instruct-20241204-042357\"\n",
    "region = \"us-east-1\"\n",
    "\n",
    "input = \"\"\"\n",
    "Generate a JSON object where:\n",
    "1. \"input\" is a single string where a user requests information for a flight from one location to another and asks about a specific day, with additional information sometimes added like number of passengers, class, if only non-stop, etc. This is provided in plain text, not JSON.\n",
    "2. \"output\" contains the corresponding Amadeus API call in JSON format:\n",
    "   - The \"action\" field is always [\"search_flights\"].\n",
    "   - The \"action_input\" field contains:\n",
    "     - \"origin\": A 3-letter city code for the departure location or airport 3 letter code if mentioned.\n",
    "     - \"destination\": A 3-letter city code for the arrival location or airport 3 letter code if mentioned.\n",
    "     - \"departure_date\": A date in \"YYYY-MM-DD\" format.\n",
    "     - \"adults\": An integer representing the number of adults (default is 1).\n",
    "     - Optional fields should be included if mentioned and returned as an empty string if not mentioned:\n",
    "       - \"return_date\": A date in \"YYYY-MM-DD\" format for the return flight.\n",
    "       - \"children\": An integer for the number of children.\n",
    "       - \"infants\": An integer for the number of infants.\n",
    "       - \"class\": One of \"ECONOMY\", \"PREMIUM_ECONOMY\", \"BUSINESS\", or \"FIRST\".\n",
    "       - \"nonStop\": A boolean indicating whether only non-stop flights are desired.\n",
    "       - \"maxPrice\": An integer specifying the maximum price.\n",
    "     - \"max\": Always set to 5.\n",
    "\n",
    "3. Generate one example per response object. Be variable in the input format and the output fields following the guidelines above.\n",
    "\"\"\"\n",
    "\n",
    "# Input data for the model\n",
    "payload = {\n",
    "    \"inputs\": \"\"\"\n",
    "Generate a JSON object where:\n",
    "1. \"input\" is a single string where a user requests information for a flight from one location to another and asks about a specific day, with additional information sometimes added like number of passengers, class, if only non-stop, etc. This is provided in plain text, not JSON.\n",
    "2. \"output\" contains the corresponding Amadeus API call in JSON format:\n",
    "   - The \"action\" field is always [\"search_flights\"].\n",
    "   - The \"action_input\" field contains:\n",
    "     - \"origin\": A 3-letter city code for the departure location or airport 3 letter code if mentioned.\n",
    "     - \"destination\": A 3-letter city code for the arrival location or airport 3 letter code if mentioned.\n",
    "     - \"departure_date\": A date in \"YYYY-MM-DD\" format.\n",
    "     - \"adults\": An integer representing the number of adults (default is 1).\n",
    "     - Optional fields should be included if mentioned and returned as an empty string if not mentioned:\n",
    "       - \"return_date\": A date in \"YYYY-MM-DD\" format for the return flight.\n",
    "       - \"children\": An integer for the number of children.\n",
    "       - \"infants\": An integer for the number of infants.\n",
    "       - \"class\": One of \"ECONOMY\", \"PREMIUM_ECONOMY\", \"BUSINESS\", or \"FIRST\".\n",
    "       - \"nonStop\": A boolean indicating whether only non-stop flights are desired.\n",
    "       - \"maxPrice\": An integer specifying the maximum price.\n",
    "     - \"max\": Always set to 5.\n",
    "\n",
    "3. Generate one example per response object. Be variable in the input format and the output fields following the guidelines above.\n",
    "\"\"\",\n",
    "    \"parameters\": {\n",
    "        \"max_length\": 50,\n",
    "        \"temperature\": 1,\n",
    "        \"stream\": \"false\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Initialize the SageMaker runtime client\n",
    "sagemaker_client = boto3.client(\"sagemaker-runtime\", region_name=region)\n",
    "\n",
    "\n",
    "examples = []\n",
    "for i in range(10):\n",
    "    # Update temperature for diversity\n",
    "    temperature = 1\n",
    "\n",
    "    # Generate a response using the system prompt\n",
    "    response = sagemaker_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    Body=json.dumps(payload),\n",
    "    ContentType=\"application/json\"\n",
    ")\n",
    "\n",
    "    # Extract the generated text\n",
    "    generated_text = response[\"Body\"].read().decode(\"utf-8\")\n",
    "\n",
    "    try:\n",
    "        # Parse the response and append it to the examples list\n",
    "        example = generated_text\n",
    "        examples.append(example)\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Failed to decode response at iteration {i + 1}: {generated_text}\")\n",
    "\n",
    "# Print all generated examples\n",
    "for idx, example in enumerate(examples):\n",
    "    print(f\"Example {idx + 1}:\")\n",
    "    print(f\"{examples[idx]}\")\n",
    "# Make the request to the endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d3aba8-9e2f-4f07-a38c-10ecf042e8e9",
   "metadata": {},
   "source": [
    "## Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "076dfd8d-0d38-40e0-8c61-89380ff91863",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [01:57<00:00, 29.45s/it]\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import json\n",
    "import re\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "\n",
    "# pipeline = transformers.pipeline(\n",
    "#     \"text-generation\",\n",
    "#     model=model_id,\n",
    "#     model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "#     device_map=\"auto\",\n",
    "# )\n",
    "\n",
    "# Use a different variable name to avoid confusion\n",
    "chat_pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device_map=\"auto\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc214c60-c7ac-4078-8c5b-654b1250a49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:38<00:00,  9.53s/it]\n",
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "# llm = transformers.pipeline(\n",
    "#     \"text-generation\",\n",
    "#     model=model_id,\n",
    "#     model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "#     device_map=\"auto\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "58fd468c-b902-4ec1-a776-27bb81c18913",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': [{'role': 'system', 'content': 'You create 1 data point in the format and structure asked by the user.'}, {'role': 'user', 'content': '\\nGenerate a JSON object where:\\n1. \"input\" is a single string where a user requests information for a flight from one location to another and asks about a specific day, with additional information sometimes added like number of passengers, class, if only non-stop, etc. This is provided in plain text, not JSON.\\n2. \"output\" contains the corresponding Amadeus API call in JSON format:\\n   - The \"action\" field is always [\"search_flights\"].\\n   - The \"action_input\" field contains:\\n     - \"origin\": A 3-letter city code for the departure location or airport 3 letter code if mentioned.\\n     - \"destination\": A 3-letter city code for the arrival location or airport 3 letter code if mentioned.\\n     - \"departure_date\": A date in \"YYYY-MM-DD\" format.\\n     - \"adults\": An integer representing the number of adults (default is 1).\\n     - Optional fields should be included if mentioned and returned as an empty string if not mentioned:\\n       - \"return_date\": A date in \"YYYY-MM-DD\" format for the return flight.\\n       - \"children\": An integer for the number of children.\\n       - \"infants\": An integer for the number of infants.\\n       - \"class\": One of \"ECONOMY\", \"PREMIUM_ECONOMY\", \"BUSINESS\", or \"FIRST\".\\n       - \"nonStop\": A boolean indicating whether only non-stop flights are desired.\\n       - \"maxPrice\": An integer specifying the maximum price.\\n     - \"max\": Always set to 5.\\n'}, {'role': 'assistant', 'content': 'Here\\'s a Python script that generates the JSON object based on the user\\'s input.\\n\\n```python\\nimport json\\n\\ndef generate_json(input_str):\\n    # Parse the input string\\n    input_parts = input_str.split()\\n    origin = None\\n    destination = None\\n    departure_date = None\\n    return_date = None\\n    adults = 1\\n    children = 0\\n    infants = 0\\n    class_ = \"ECONOMY\"\\n    nonStop = False\\n    maxPrice = 0\\n\\n    for i, part in enumerate(input_parts):\\n        if part.upper() in [\"FROM\", \"DEPARTURE\"]:\\n            origin = input_parts[i + 1]\\n        elif part.upper() in [\"TO\", \"ARRIVAL\"]:\\n            destination = input_parts[i + 1]\\n        elif part.upper() in [\"ON\", \"DATE\"]:\\n            departure_date = input_parts[i + 1]\\n        elif part.upper() == \"RETURN\":\\n            return_date = input_parts[i + 1]\\n        elif part.upper() == \"ADULTS\":\\n            adults = int(input_parts[i + 1])\\n        elif part.upper() == \"CHILDREN\":\\n            children = int(input_parts[i + 1])\\n        elif part.upper() =='}]}]\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You create 1 data point in the format and structure asked by the user.\"},\n",
    "    {\"role\": \"user\", \"content\": \"\"\"\n",
    "Generate a JSON object where:\n",
    "1. \"input\" is a single string where a user requests information for a flight from one location to another and asks about a specific day, with additional information sometimes added like number of passengers, class, if only non-stop, etc. This is provided in plain text, not JSON.\n",
    "2. \"output\" contains the corresponding Amadeus API call in JSON format:\n",
    "   - The \"action\" field is always [\"search_flights\"].\n",
    "   - The \"action_input\" field contains:\n",
    "     - \"origin\": A 3-letter city code for the departure location or airport 3 letter code if mentioned.\n",
    "     - \"destination\": A 3-letter city code for the arrival location or airport 3 letter code if mentioned.\n",
    "     - \"departure_date\": A date in \"YYYY-MM-DD\" format.\n",
    "     - \"adults\": An integer representing the number of adults (default is 1).\n",
    "     - Optional fields should be included if mentioned and returned as an empty string if not mentioned:\n",
    "       - \"return_date\": A date in \"YYYY-MM-DD\" format for the return flight.\n",
    "       - \"children\": An integer for the number of children.\n",
    "       - \"infants\": An integer for the number of infants.\n",
    "       - \"class\": One of \"ECONOMY\", \"PREMIUM_ECONOMY\", \"BUSINESS\", or \"FIRST\".\n",
    "       - \"nonStop\": A boolean indicating whether only non-stop flights are desired.\n",
    "       - \"maxPrice\": An integer specifying the maximum price.\n",
    "     - \"max\": Always set to 5.\n",
    "\"\"\"}\n",
    "]\n",
    "\n",
    "# Generate output using the chat pipeline\n",
    "outputs = chat_pipeline(\n",
    "    messages,\n",
    "    max_new_tokens=256,\n",
    ")\n",
    "\n",
    "print(outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "19c144ad-dd3e-4fec-b22e-a4d7a2e9e141",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to decode JSON at iteration 1: ```json\n",
      "{\n",
      "  \"input\": \"Flight from LAX to JFK on 2024-07-27 for 2 adults and 1 child in economy class with non-stop flights only\",\n",
      "  \"output\": {\n",
      "    \"action\": [\"search_flights\"],\n",
      "    \"action_input\": {\n",
      "      \"origin\": \"LAX\",\n",
      "      \"destination\": \"JFK\",\n",
      "      \"departure_date\": \"2024-07-27\",\n",
      "      \"adults\": \"2\",\n",
      "      \"children\": \"1\",\n",
      "      \"class\": \"ECONOMY\",\n",
      "      \"nonStop\": \"true\",\n",
      "      \"max\": \"5\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "This JSON object represents a user's request for flights from LAX to JFK on July 27, 2024, for 2 adults and 1 child in economy class with non-stop flights only. The corresponding Amadeus API call is also provided in JSON format.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to decode JSON at iteration 2: Here's a Python script to generate the JSON object based on the user's input:\n",
      "\n",
      "```python\n",
      "import json\n",
      "import re\n",
      "\n",
      "def generate_amadeus_api_call(input_str):\n",
      "    # Regular expression to extract information from the input string\n",
      "    pattern = r\"from\\s+([A-Z]{3})\\s+to\\s+([A-Z]{3})\\s+on\\s+([A-Za-z]{3}\\s+\\d{1,2},\\s\\d{4})\\s*(.*)\"\n",
      "    match = re.match(pattern, input_str)\n",
      "    \n",
      "    if match:\n",
      "        origin = match.group(1)\n",
      "        destination = match.group(2)\n",
      "        departure_date = match.group(3).replace(\",\", \"\").replace(\" \", \"-\")\n",
      "        additional_info = match.group(4)\n",
      "        \n",
      "        adults = 1\n",
      "        return_date = \"\"\n",
      "        children = \"\"\n",
      "        infants = \"\"\n",
      "        class_ = \"\"\n",
      "        nonStop = \"\"\n",
      "        maxPrice = \"\"\n",
      "        \n",
      "        # Parse additional information\n",
      "        if additional_info:\n",
      "            words = additional_info.split()\n",
      "            for word in words:\n",
      "                if word.isdigit():\n",
      "                    adults = int(word)\n",
      "                elif word.upper() == \"CHILDREN\":\n",
      "                    children = \"1\"\n",
      "                elif word.upper() ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to decode JSON at iteration 3: Here's a Python function to generate the JSON object as per the given requirements:\n",
      "\n",
      "```python\n",
      "import json\n",
      "\n",
      "def generate_api_call(input_str):\n",
      "    \"\"\"\n",
      "    Generate Amadeus API call in JSON format based on the input string.\n",
      "\n",
      "    Args:\n",
      "        input_str (str): A string containing user's flight request.\n",
      "\n",
      "    Returns:\n",
      "        dict: A dictionary containing the API call in JSON format.\n",
      "    \"\"\"\n",
      "    # Split the input string into words to extract relevant information\n",
      "    words = input_str.split()\n",
      "\n",
      "    origin = None\n",
      "    destination = None\n",
      "    departure_date = None\n",
      "    return_date = None\n",
      "    adults = 1\n",
      "    children = 0\n",
      "    infants = 0\n",
      "    class_ = None\n",
      "    non_stop = False\n",
      "    max_price = None\n",
      "\n",
      "    for i, word in enumerate(words):\n",
      "        if word.upper() in [\"FROM\", \"TO\"]:\n",
      "            origin = words[i-1]\n",
      "            destination = words[i+1]\n",
      "        elif word.upper() == \"ON\":\n",
      "            departure_date = words[i+1]\n",
      "        elif word.upper() == \"RETURN\":\n",
      "            return_date = words[i+1]\n",
      "        elif word.upper() == \"ADULTS\":\n",
      "            adults = int(words[i+1])\n",
      "        elif word\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to decode JSON at iteration 4: Here's a Python script to generate the JSON object based on the user's input:\n",
      "\n",
      "```python\n",
      "import json\n",
      "\n",
      "def generate_amadeus_api_call(input_string):\n",
      "    # Parse the input string\n",
      "    input_parts = input_string.split()\n",
      "    origin = input_parts[0]\n",
      "    destination = input_parts[1]\n",
      "    departure_date = input_parts[2]\n",
      "    adults = 1\n",
      "    children = 0\n",
      "    infants = 0\n",
      "    class_type = \"ECONOMY\"\n",
      "    nonStop = False\n",
      "    maxPrice = 0\n",
      "    return_date = \"\"\n",
      "\n",
      "    # Parse additional information\n",
      "    for part in input_parts[3:]:\n",
      "        if part == \"return\":\n",
      "            return_date = input_parts[input_parts.index(part) + 1]\n",
      "        elif part == \"children\":\n",
      "            children = int(input_parts[input_parts.index(part) + 1])\n",
      "        elif part == \"infants\":\n",
      "            infants = int(input_parts[input_parts.index(part) + 1])\n",
      "        elif part == \"class\":\n",
      "            class_type = input_parts[input_parts.index(part) + 1]\n",
      "        elif part == \"non-stop\":\n",
      "            nonStop = True\n",
      "        elif part == \"max\":\n",
      "            maxPrice = int(input_parts[input_parts.index(part)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to decode JSON at iteration 5: Here's a Python script that generates the JSON object based on the user's input:\n",
      "\n",
      "```python\n",
      "import json\n",
      "\n",
      "def generate_json(input_str):\n",
      "    # Parse the input string\n",
      "    words = input_str.split()\n",
      "    origin = None\n",
      "    destination = None\n",
      "    departure_date = None\n",
      "    return_date = None\n",
      "    adults = 1\n",
      "    children = 0\n",
      "    infants = 0\n",
      "    class_type = \"ECONOMY\"\n",
      "    nonStop = False\n",
      "    maxPrice = 0\n",
      "\n",
      "    for word in words:\n",
      "        if word.upper() in [\"FROM\", \"TO\"]:\n",
      "            origin = words[words.index(word) + 1][:3]\n",
      "            destination = words[words.index(word) + 2][:3]\n",
      "        elif word.upper() in [\"ON\", \"FOR\"]:\n",
      "            departure_date = words[words.index(word) + 1][:10]\n",
      "        elif word.upper() in [\"RETURN\", \"BACK\"]:\n",
      "            return_date = words[words.index(word) + 1][:10]\n",
      "        elif word.upper() in [\"ADULTS\", \"PASSENGERS\"]:\n",
      "            adults = int(words[words.index(word) + 1])\n",
      "        elif word.upper() in [\"CHILDREN\"]:\n",
      "            children = int\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to decode JSON at iteration 6: Here's a Python function to generate the JSON object based on the user's input:\n",
      "\n",
      "```python\n",
      "import json\n",
      "from datetime import datetime\n",
      "\n",
      "def generate_amadeus_api_call(input_str):\n",
      "    # Parse the input string\n",
      "    input_str = input_str.strip()\n",
      "    \n",
      "    # Split the input string into words\n",
      "    words = input_str.split()\n",
      "    \n",
      "    # Initialize variables\n",
      "    origin = ''\n",
      "    destination = ''\n",
      "    departure_date = ''\n",
      "    return_date = ''\n",
      "    adults = 1\n",
      "    children = 0\n",
      "    infants = 0\n",
      "    class_type = 'ECONOMY'\n",
      "    non_stop = False\n",
      "    max_price = 0\n",
      "    \n",
      "    # Find the origin\n",
      "    for word in words:\n",
      "        if word[0].isupper():\n",
      "            origin = word\n",
      "            break\n",
      "    \n",
      "    # Find the destination\n",
      "    for word in words:\n",
      "        if word!= origin and word[0].isupper():\n",
      "            destination = word\n",
      "            break\n",
      "    \n",
      "    # Find the departure date\n",
      "    for word in words:\n",
      "        try:\n",
      "            departure_date = datetime.strptime(word, '%Y-%m-%d').strftime('%Y-%m-%d')\n",
      "            break\n",
      "        except ValueError:\n",
      "            pass\n",
      "    \n",
      "    # Find the return date\n",
      "    for word\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to decode JSON at iteration 7: Here's a Python function to generate the JSON object based on the user's input:\n",
      "\n",
      "```python\n",
      "import json\n",
      "\n",
      "def generate_amadeus_api_call(input_string):\n",
      "    # Parse the input string\n",
      "    words = input_string.split()\n",
      "    origin = None\n",
      "    destination = None\n",
      "    departure_date = None\n",
      "    return_date = None\n",
      "    adults = 1\n",
      "    children = 0\n",
      "    infants = 0\n",
      "    class_type = None\n",
      "    non_stop = False\n",
      "    max_price = None\n",
      "\n",
      "    for i, word in enumerate(words):\n",
      "        if word.upper() in [\"FROM\", \"FROMTO\"]:\n",
      "            origin = words[i+1][:3].upper()\n",
      "        elif word.upper() in [\"TO\", \"ARRIVAL\"]:\n",
      "            destination = words[i+1][:3].upper()\n",
      "        elif word.upper() in [\"ON\", \"DATE\"]:\n",
      "            departure_date = words[i+1]\n",
      "        elif word.upper() in [\"RETURN\", \"BACK\"]:\n",
      "            return_date = words[i+1]\n",
      "        elif word.upper() == \"ADULTS\":\n",
      "            adults = int(words[i+1])\n",
      "        elif word.upper() == \"CHILDREN\":\n",
      "            children = int(words[i+1])\n",
      "        elif word.upper() == \"INFANTS\":\n",
      "           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to decode JSON at iteration 8: Here is an example JSON object based on your request:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"input\": \"Flight from LAX to JFK on 2024-07-25 for 2 adults and 1 child, non-stop, economy class\",\n",
      "  \"output\": {\n",
      "    \"action\": [\"search_flights\"],\n",
      "    \"action_input\": {\n",
      "      \"origin\": \"LAX\",\n",
      "      \"destination\": \"JFK\",\n",
      "      \"departure_date\": \"2024-07-25\",\n",
      "      \"adults\": 2,\n",
      "      \"children\": 1,\n",
      "      \"class\": \"ECONOMY\",\n",
      "      \"nonStop\": true,\n",
      "      \"max\": 5\n",
      "    }\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "Here's another example with a return date and a maximum price:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"input\": \"Flight from LAX to JFK on 2024-07-25 and return on 2024-07-30 for 2 adults, non-stop, economy class with a max price of 500\",\n",
      "  \"output\": {\n",
      "    \"action\": [\"search_flights\"],\n",
      "    \"action_input\": {\n",
      "      \"origin\": \"LAX\",\n",
      "      \"destination\": \"JFK\",\n",
      "      \"departure_date\": \"2024-07-25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to decode JSON at iteration 9: Here's an example JSON object based on the input string \"Flight from New York (JFK) to Los Angeles (LAX) on 2024-07-25, non-stop, economy class for 2 adults and 1 child\".\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"input\": \"Flight from New York (JFK) to Los Angeles (LAX) on 2024-07-25, non-stop, economy class for 2 adults and 1 child\",\n",
      "  \"output\": {\n",
      "    \"action\": [\"search_flights\"],\n",
      "    \"action_input\": {\n",
      "      \"origin\": \"JFK\",\n",
      "      \"destination\": \"LAX\",\n",
      "      \"departure_date\": \"2024-07-25\",\n",
      "      \"adults\": \"2\",\n",
      "      \"class\": \"ECONOMY\",\n",
      "      \"children\": \"1\",\n",
      "      \"nonStop\": \"true\",\n",
      "      \"max\": \"5\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "Here's another example based on the input string \"Flight from Paris (CDG) to Tokyo (NRT) on 2024-08-01 for 3 adults with a maximum price of 1000 USD\".\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"input\": \"Flight from Paris (CDG) to Tokyo\n",
      "Failed to decode JSON at iteration 10: Here's a Python script to generate the JSON object based on the user's input:\n",
      "\n",
      "```python\n",
      "import json\n",
      "\n",
      "def generate_amadeus_api_call(user_input):\n",
      "    # Split the user input into individual parameters\n",
      "    params = user_input.split()\n",
      "\n",
      "    # Initialize the action and action_input\n",
      "    action = [\"search_flights\"]\n",
      "    action_input = {}\n",
      "\n",
      "    # Extract the origin and destination\n",
      "    origin = params[0]\n",
      "    destination = params[1]\n",
      "    action_input[\"origin\"] = origin\n",
      "    action_input[\"destination\"] = destination\n",
      "\n",
      "    # Extract the departure date\n",
      "    departure_date = params[2]\n",
      "    action_input[\"departure_date\"] = departure_date\n",
      "\n",
      "    # Extract the number of adults\n",
      "    adults = 1\n",
      "    for param in params:\n",
      "        if param.isdigit():\n",
      "            adults = int(param)\n",
      "            break\n",
      "    action_input[\"adults\"] = adults\n",
      "\n",
      "    # Extract optional parameters\n",
      "    return_date = \"\"\n",
      "    children = \"\"\n",
      "    infants = \"\"\n",
      "    class_ = \"\"\n",
      "    nonStop = \"\"\n",
      "    maxPrice = \"\"\n",
      "\n",
      "    for param in params:\n",
      "        if param == \"return\":\n",
      "            return_date = params[params.index(\"return\") + 1]\n",
      "        elif param == \"children\":\n",
      "            children = params[\n"
     ]
    }
   ],
   "source": [
    "# Store generated examples\n",
    "examples = []\n",
    "\n",
    "# Loop to generate 10 examples\n",
    "for i in range(10):\n",
    "    try:\n",
    "        # Call the pipeline with the defined messages as a positional argument\n",
    "        outputs = chat_pipeline(\n",
    "            messages,\n",
    "            max_new_tokens=256,\n",
    "        )\n",
    "\n",
    "        # Extract the assistant's content from the outputs\n",
    "        assistant_content = outputs[0][\"generated_text\"][-1]['content']\n",
    "\n",
    "        # Extract JSON block corresponding to assistant content\n",
    "        json_match = re.search(r\"json\\n(.*?)\\n\", assistant_content, re.DOTALL)\n",
    "        if json_match:\n",
    "            json_text = json_match.group(1)\n",
    "            # Parse JSON and append to examples\n",
    "            example = json.loads(json_text)\n",
    "            examples.append(example)\n",
    "        else:\n",
    "            print(f\"No valid JSON found at iteration {i + 1}\")\n",
    "\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Failed to decode JSON at iteration {i + 1}: {assistant_content}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during generation at iteration {i + 1}: {str(e)}\")\n",
    "\n",
    "# Pretty-print all valid JSON examples\n",
    "for idx, example in enumerate(examples):\n",
    "    print(f\"Example {idx + 1}:\")\n",
    "    print(json.dumps(example, indent=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llama_env)",
   "language": "python",
   "name": "llama_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
